type,title,abstract,year,keywords,filename,id
InProceedings,Human evaluation of robot-generated spatial descriptions,"We describe a system where the semantics of spatial referential expressions have been automatically learned by finding mappings between symbolic natural language descriptions of the environment and non-symbolic representations from the sensory data of a mobile robot used for localisation and map building (SLAM). Although the success of learning can be measured by examining classifier performance on held-out data, this does not in itself guarantee that the descriptions generated will be natural and informative for a human observer. In this paper we describe the results of an evaluation of our embodied robotic system by human observers. Key words: spatial expressions, machine learning, mobile robots, embod- ied multi-modal conversational agents, evaluation.",2010,NA,025.pdf,025
Book,Multi-agent system (MAS) applications in ambient intelligence (AmI) environments,"Research in context-aware systems has been moving towards reusable and adaptable architectures for managing more advanced human-computer interfaces. Ambient. Intelligence (AmI) investigates computer-based services, which are ubiquitous and based on a variety of objects and devices. Their intelligent and intuitive interfaces act as mediators through which people can interact with the ambient environment. In this paper we present an agent-based architecture which supports the execution of agents in AmI environments. Two case studies are also presented, an airport information system and a railway information system, which uses spoken conversational agents to respond to the userâ€™s requests using the contextual information that includes the location information of the user. Â© Springer-Verlag Berlin Heidelberg 2010.",2010,"Mobile context-aware systems, Multi-agent systems, Services oriented architectures",037.pdf,037
InProceedings,Optimizing situated dialogue management in unknown environments,"We present a conversational learning agent that helps users navigate through complex and challenging spatial environments. The agent exhibits adaptive behaviour by learning spatiallyaware dialogue actions while the user carries out the navigation task. To this end, we use Hierarchical Reinforcement Learning with relational representations to efficiently optimize dialogue actions tightly-coupled with spatial ones, and Bayesian networks to model the user's beliefs of the navigation environment. Since these beliefs are continuously changing, we induce the agent's behaviour in real time. Experimental results, using simulation, are encouraging by showing efficient adaptation to the user's navigation knowledge, specifically to the generated route and the intermediate locations to negotiate with the user. Copyright Â© 2011 ISCA.",2011,"Situated interaction, Bayesian networks, Hierarchical control, Reinforcement learning, Spoken dialogue systems",039.pdf,039
InProceedings,Conversational natural language interaction for place-related knowledge acquisition,"We focus on the problems of using Natural Language interaction to support pedestrians in their place-related knowledge acquisition. Our case study for this discussion is a smartphone-based Natural Language interface that allows users to acquire spatial and cultural knowledge of a city. The framework consists of a spoken dialogue-based information system and a smartphone client. The system is novel in combining geographic information system (GIS) modules such as a visibility engine with a question-answering (QA) system. Users can use the smart-phone client to engage in a variety of interleaved conversations such as navigating from A to B, using the QA functionality to learn more about points of interest (PoI) nearby, and searching for amenities and tourist attractions. This system explores a variety of research questions involving Natural Language interaction for acquisition of knowledge about space and place.",2012,NA,018.pdf,018
Article,Modeling and communicating the conceptual intent of geo-analytical tasks for human-GIS interaction,"One of the fundamental issues of geographical information science is to design GIS interfaces and functionalities in a way that is easy to understand, teach, and use. Unfortunately, current geographical information systems (including ArcGIS) remains very difficult to use as spatial analysis tools, because they organize and expose functionalities according to GIS data structures and processing algorithms. As a result, GIS interfaces are conceptually confusing, cognitively complex, and semantically disconnected from the way human reason about spatial analytical activities. In this article, we propose an approach that structures GIS analytical functions based on the notion of {""}analytical intent{""}. We describe an experiment that replaces ArcGIS desktop interface with a conversational interface, to enable mixed-initiative user-system interactions at the level of analytical intentions. We initially focus on the subset of GIS functions that are relevant to {""}finding what's inside{""} as described by Mitchell, but the general principles apply to other types of spatial analysis. This work demonstrates the feasibility of delegating some spatial thinking tasks to computational agents, and also raises future research questions that are key to building a better theory of spatial thinking with GIS. Â© 2013 John Wiley \& Sons Ltd.",2013,NA,035.pdf,035
InProceedings,Trip 4 All: A Gamified App to Provide a New Way to Elderly People to Travel,"Older adults have much to gain from bringing technology into their daily lives. The extent to which this is possible strongly depends on careful design and accessible, easy to use products, developed using an elderly centered methodology. The senior tourism is a market in expansion and the old travelers need new and innovative technologies to help and support their trips. These technologies should contribute to a fun and safe experience, while promoting feelings of pleasure and self realization. In this paper we follow this design approach and put it to the test in developing the {""}Trip 4 All{""}(T4A), an application that works as a gamified virtual assistant to the elderly during a walking tourist visit. The gamified interaction with the visited environment intend to improve motivation to accomplish the visit and make the content absorption more fun and easier. The T4A works on georeferenced maps where the users' geoposition is a trigger to launch storytelling content and/or challenges based on the aspects of the visited site as such: geographical, art, religious, historic, cultural and human. The success in the challenges give the user prizes, new resources and abilities to try more complex challenges that brings more valuable prizes and so on. Furthermore, the proposed application intend to work as a companion that provides self confidence, support and social integration to elderly tourists. Â© 2015 The Authors.",2015,"Active Aging, Elderly-centred design, Iterative development method, Mobile application evaluation",047.pdf,047
InProceedings,Remembering what you said: Semantic personalized memory for personal digital assistants,Personal digital assistants are designed to assist users in easy information retrieval or execute the tasks they are interested in. The conversational medium implies an additional level of intelligence but typically these systems do not support any reference to the user's past interactions. We propose a domain-agnostic approach that enables the system to address queries referring to the past by using an information retrieval approach to rank various entities for a given query. We also add semantic enrichment to the recall process by augmenting the entities with information from a knowledge graph and leverage that in the retrieval process. We mined user interactions for the Cortana digital assistant to extract queries with location and business entities and show that our technique can achieve an accuracy of 89.8\% for such recall queries. Â© 2017 IEEE.,2017,"dialog management, information retrieval, Personal digital assistants, referring expressions, spoken language understanding",044.pdf,044
InProceedings,Using knowledge graph and search query click logs in statistical language model for speech recognition,"This paper demonstrates how Knowledge Graph (KG) and Search Query Click Logs (SQCL) can be leveraged in statistical language models to improve named entity recognition for online speech recognition systems. Due to the missing in the training data, some named entities may be recognized as other common words that have the similar pronunciation. KG and SQCL cover comprehensive and fresh named entities and queries that can be used to mitigate the wrong recognition. First, all the entities located in the same area in KG are clustered together, and the queries that contain the entity names are selected from SQCL as the training data of a geographical statistical language model for each entity cluster. These geographical language models make the unseen named entities less likely to occur during the model training, and can be dynamically switched according to the user location in the recognition phase. Second, if any named entities are identified in the previous utterances within a conversational dialog, the probability of the n-best word sequence paths that contain their related entities will be increased for the current utterance by utilizing the entity relationships from KG and SQCL. This way can leverage the long-Term contexts within the dialog. Experiments for the proposed approach on voice queries from a spoken dialog system yielded a 12.5\% relative perplexity reduction in the language model measurement, and a 1.1\% absolute word error rate reduction in the speech recognition measurement. Copyright Â© 2017 ISCA.",2017,"knowledge graph, named entity recognition, search query click log, speech recognition, statistical language model",048.pdf,048
Article,"Smart tourist information points by combining agents, semantics and AI techniques","The tourism sector in the province of Teruel (Aragon, Spain) is increasing rapidly. Although the number of domestic and foreign tourists is continuously growing, there are some tourist attractions spread over a wide geographical area, which are only visited by a few people at specific times of the year. Additionally, having human tourist guides everywhere and speaking different languages is unfeasible. An integrated solution based on smart and interactive Embodied Conversational Agents (ECAs) tourist guides combined with ontologies would overcome this problem. This paper presents a smart tourist information points approach which gathers tourism information about Teruel, structured according to a novel lightweight ontology built on OWL (Ontology Web Language), known as TITERIA (Touristic Information of TEruel for Intelligent Agents). Our proposal, which combines TITERIA with the Maxine platform, is capable of responding appropriately to the users thanks to its Artificial Intelligence Modeling Language (AIML) database and the AI techniques added to Maxine. Preliminary results indicate that our prototype is able to inform users about interesting topics, as well as to propose other related information, allowing them to acquire a complete information about any issue. Furthermore, users can directly talk with an artificial actor making communication much more natural and closer. Â© 2017, ComSIS Consortium. All rights reserved.",2017,"Virtual human, Embodied conversational agent, Ontology, Tourism",045.pdf,045
InProceedings,From linguistic linked open data to multimodal natural interaction: A case study,"We present here the conversion of Linguistic Linked Open Data into Semantic Maps to be used to produce contents in a set of technological applications for Cultural Heritage. The paper describes the architectural data collection and annotation procedure adopted in the Cultural Heritage Orienting Multimodal Experiences (CHROME) project (PRIN 2015 funded by Italian University and Research Ministry). Such data will be used in Multimodal Dialogue Systems to obtain precise information about Architectural Heritage, by means of pointing gestures or verbal requests. In particular, we design conversational agents accessing fine-detailed semantic data linked to available 3D models of historical buildings. The starting point of our scientific approach is the Getty Vocabulary on Art \& Architecture Thesaurus, integrated with the Getty Thesaurus of Geographic Names (TGN) and the Union List of Artist Names (ULAN). These data are related to 3D mesh of the considered buildings in order to associate abstract concepts to architectural elements. In the field of 3D architectural investigation, a significant amount of research has been conducted to allow domain experts to represent semantic data while keeping spatial references. We will discuss how this will make it possible to support multimodal user interaction and generate Cultural Heritage presentations. Â© 2018 IEEE.",2018,"Data model, Multimodal interaction, vocabularies BASED ONTOLOGY",024.pdf,024
InProceedings,Cognitive Spatial Representative Map for Interactive Conversational Model of Service Robot,"Assistive robots are developed for supporting the daily activities of human beings to uplift the living standards. Assistive robots should be friendly, reliable, active, comprehensible and capable of creating interactive conversations with users in order to be a friendly companion for the human. Humans tend to include uncertain terms related to directions and distances to describe or express ideas. Furthermore, an assistive robot should be capable of analyzing and understanding the numerical meaning of uncertain terms for the purpose of creating a cognitive map in order to build friendly interactions between the user and the robot. Moreover, this paper proposes a method to identify the spatial relation between the objects in a given environment and describes such environments using uncertain terms related to spatial information based on a cognitive map created by the proposed system while having interactive conversations with the user. Conversation Management Module (CMM) and Spatial Information Processor (ISP) and Cognitive Map Creator (CMC) have been introduced in order to create interactive conversations while processing the uncertain information based on a cognitive map. Capabilities of the robot has been demonstrated and validated from the experimental result. Â© 2018 IEEE.",2018,"cognitive map, conversation model, Human robot interaction, social robotics",015.pdf,015
InProceedings,Improving object disambiguation from natural language using empirical models,"Robots, virtual assistants, and other intelligent agents need to effectively interpret verbal references to environmental objects in order to successfully interact and collaborate with humans in complex tasks. However, object disambiguation can be a challenging task due to ambiguities in natural language. To reduce uncertainty when describing an object, humans often use a combination of unique object features and locative prepositions-prepositional phrases that describe where an object is located relative to other features (i.e., reference objects) in a scene. We present a new system for object disambiguation in cluttered environments based on probabilistic models of unique object features and spatial relationships. Our work extends prior models of spatial relationship semantics by collecting and encoding empirical data from a series of crowdsourced studies to better understand how and when people use locative prepositions, how reference objects are chosen, and how to model prepositional geometry in 3D space (e.g., capturing distinctions between â€œnext toâ€ and â€œbesideâ€). Our approach also introduces new techniques for responding to compound locative phrases of arbitrary complexity and proposes a new metric for disambiguation confidence. An experimental validation revealed our method can improve object disambiguation accuracy and performance over past approaches. Â© 2018 Copyright held by the owner/author(s).",2018,"Grounding, Locative prepositions, Natural language disambiguation",026.pdf,026
InProceedings,Citicafe: An interactive interface for citizen engagement,"Community engagement is a new and emerging trend in urban cities driven by the mission of developing responsible citizenship. Technology is playing a vital role in helping this mission. For example, over the last couple of years, there have been a plethora of social media avenues to report civic issues and complaints. We present one such contribution of technology, in terms of an intelligent platform, {""}Citicafe{""}. The platform has a conversation based interface that enhances citizen engagement by enabling a direct communication with them. The platform ingests data from different sources, which is exploited by a virtual agent to enable informed interactions. It can help citizens to (a) report problems and (b) gather information related to civic issues for different locations and their neighborhoods. We report the results of a user study carried out to establish the effectiveness of our interface and draw a comparison with an existing platform. A detailed qualitative and quantitative analysis of the survey results shows a definite and statistically significant (p {\textless} 0.05) preference for our interface over the existing platform. Â© 2018 Copyright held by the owner/author(s). Publication rights licensed to ACM.",2018,"Conversational agent, Citizen engagement, Clustering, CRF, Knowledge mining, Natural language, Social good, Topic modeling",011.pdf,011
InProceedings,Improving reverse geocoding: Localization of blind pedestrians using conversational UI,"Geolocation services suffer from low precision in urban environments mainly due to sky occlusion and signal reflections from buildings, which is the key disadvantage of current navigation assistive AIDS for blind pedestrians. We designed a method that improves reverse geocoding to the level, at which the system can differentiate sides of the street where the blind user is traveling. By implementing a conversational user interface to ask the user about important landmarks and in combination with coarse location and heading, we achieved a usable, accessible and acceptable solution. The number of address points candidates can be reduced by 50 \% to those on the corresponding side of the street. A qualitative field study with six visually impaired participants confirmed acceptance by the user group and accessibility and usability of the method. Â© 2017 IEEE.",2018,NA,027.pdf,027
Book,Code Hunting Games: A Mixed Reality Multiplayer Treasure Hunt Through a Conversational Interface,"In this paper, we describe an online multi-player game that challenges players with abstract coding puzzles that are tied to a geographical location. The proposed system transposes the classical scheme of â€œtreasure huntâ€ games into a mixed-reality game, where players must physically move in order to advance in the game, while at the same time interacting with a chatbot through an online messaging system. The implementation of the online game is described in detail and an overview of different deployments of the system is given, including a large-scale deployment during the European CodeWeek 2017. We discuss details of the proposed system, including lessons learned during the development and operation of the game. We also argue that mobile games like the one proposed can be successfully adopted for many different purposes, from entertainment to education. Â© 2018, Springer International Publishing AG, part of Springer Nature.",2018,"Bots, Conversational UI, Instant messaging, Mixed reality, Mobile gaming",014.pdf,014
InProceedings,Raiden11@IECSIL-FIRE-2018: Named entity recognition for Indian languages,"This paper presents our solution for the Named Entity Recognition (NER) task for the Information Extractor for Conversational Systems in Indian Languages challenge (IECSIL) [5] of the FIRE 2018 conference. A subset of the Information Extraction (IE) task, NER is a key to extract information and semantics of the text from unstructured data. The objective of NER is the identification and classification of every word or token in a document into predefined categories such as names of person, location, organization, etc. For this challenge the dataset provided by IECSIL [4] comprised of multilingual text of various Indian languages like Hindi, Tamil, Malayalam, Telugu, and Kannada. We mainly focus on the identification and classification of named entities belonging to nine categories like Name, Location, Datenum, etc. We tried linear models like Naive Bayes and SVM, and also a simple Neural Network to solve this problem. The best results are achieved by the simple neural network with an accuracy of 90.33\% for all languages combined. This indicates that different advanced neural networks could be possible solutions to further improve this accuracy. Â© 2018 CEUR-WS. All Rights Reserved.",2018,"Information Extraction, Named Entity Recognition, Neural Networks, Word Embeddings",043.pdf,043
InProceedings,Building intelligent virtual agents as conversational partners in digital construction sites,"Construction-related professionals are required to interact constantly on a variety of complex spatiotemporal occasions with several groups of people (e.g., architects, engineers, other construction professionals). The efficiency and effectiveness of the construction process strongly depends on the successful communication of information between all the functional groups involved in the different contexts of construction projects. However, lack of exposure to construction processes and construction professionals is widely observed in construction graduates. This lack of exposure results in deficient understanding of construction domain concepts in relation to real world problems. The use of intelligent virtual agents powered by building information modeling (BIM)-based virtual environments provides opportunities to incorporate conversational practices into classroom teaching. By employing these virtual interactions, a consequence-free environment that is controllable, representative, and repeatable can be achieved, with the benefit of providing constant real-time feedback to students. In such digital settings, students can observe spatiotemporal dependent occasions and communicate with other virtual professionals to obtain a better understanding of the construction events. In this paper, the technical workflow to create this virtual communication platform will be described in detail. This workflow includes (1) procedure of generating and authoring a virtual agent with its corresponding layers of information, (2) the creation process of the virtual environment that corresponds the conversational contexts using BIM-based technologies, and (3) the integration of the intelligent virtual agent and the digital site into a working platform. A case study is used to illustrate the conversational practice platform workflow for a high-risk caught-in or -between hazard scenario. Â© 2018 American Society of Civil Engineers (ASCE). All rights reserved.",2018,NA,010.pdf,010
InProceedings,SSN\_NLp@IECSIL-FIRE-2018: Deep learning approach to named entity recognition and relation extraction for conversational systems in Indian languages,"Named Entity Recognition (NER) focuses on the classification of proper nouns into the generic named entities (NE) such as person\_names, organizations, locations, currency and dates. NER has several applications like conversation systems, machine translation, automatic summarization and question answering. Relation Extraction (RE) is an information extraction process used to identify the relationship between NEs. RE is very important in applications like short answer grading, conversation systems, question answering and ontology learning. NER and RE in Indian languages are difficult tasks due to their agglutinative nature and rich morphological structure. Further, developing language independent framework that supports all Indian Languages is a challenging task. In this paper, we present a deep learning methodology for both NER and RE in five Indian languages namely Hindi, Kannada, Malayalam, Tamil and Telugu. We proposed a common approach that works for both NER and RE tasks. We have used neural machine translation architecture to implement our methodology for these tasks. Our approach was evaluated using the data set given by IECSIL@FIRE2018 shared task. We have evaluated on two sets of data for NER task and obtained the accuracies as 94.41\%, 95.23\%, 95.97\% and 96.02\% for the four variations on pre-evaluation test set and 95.9\%, 95.85\% and 95.05\% for the three runs on final-evaluation test set. Also, for RE task, we have obtained the accuracies as 56.19\%, 60.74\%, 60.7\%, 75.43\% and 79.11\% for our five variations on pre-evaluation test set and 79.44\%, 76.01\% and 61.11\% for Run 1, Run 2 and Run 3 respectively on final-evaluation test set. Â© 2018 CEUR-WS. All Rights Reserved.",2018,"Information Extraction, Deep Learning, Indian Languages, Named Entity Recognition (NER), Relation Extraction, Text mining",046.pdf,046
Article,A dialogue based mobile virtual assistant for tourists: The SpaceBook Project,"Ubiquitous mobile computing offers innovative approaches in the delivery of information that can facilitate free roaming of the city, informing and guiding the tourist as the city unfolds before them. However making frequent visual reference to mobile devices can be distracting, the user having to interact via a small screen thus disrupting the explorative experience. This research reports on an EU funded project, SpaceBook, that explored the utility of a hands-free, eyes-free virtual tour guide, that could answer questions through a spoken dialogue user interface and notify the user of interesting features in view while guiding the tourist to various destinations. Visibility modelling was carried out in real-time based on a LiDAR sourced digital surface model, fused with a variety of map and crowd sourced datasets (e.g. Ordnance Survey, OpenStreetMap, Flickr, Foursquare) to establish the most interesting landmarks visible from the user's location at any given moment. A number of variations of the SpaceBook system were trialled in Edinburgh (Scotland). The research highlighted the pleasure derived from this novel form of interaction and revealed the complexity of prioritising route guidance instruction alongside identification, description and embellishment of landmark information â€“ there being a delicate balance between the level of information â€˜pushedâ€™ to the user, and the user's requests for further information. Among a number of challenges, were issues regarding the fidelity of spatial data and positioning information required for pedestrian based systems â€“ the pedestrian having much greater freedom of movement than vehicles. Â© 2017",2018,"Location based service, Spoken Dialogue System, Viewshed, Virtual city guide",001.pdf,001
Article,A robust artificial intelligence: smart indoor positioning system,"Over the previous few centuries, technology has converted massively from being a desktop personal computer to handheld mobile phones, with lower energy consumption of raw computing power. This computability is now incorporated with other systems as well as isolated to a single device. This paradigm was first noted in cyber-physical systems with the introduction of cloud services. The evolution of Artificial Intelligence(AI) with cloud computing and the importance of this field in human life, induce us to make simple and efficient talkative assistant robot for indoor navigation. The navigation system in outdoor typically rely upon Global Positioning System (GPS) but the indoor navigation systems have to rely on different technologies, as GPS signals cannot be received indoors. Thus, several technologies have been proposed and implemented over the past decade to improve navigation in indoors. But they were costly and less effective. Therefore, we have proposed a system that assists humans to find their location in a conversational manner. The suggested system was constructed by introducing the advantages of a personal assistant device, Amazon Alexa, the cloud services of Amazon and its voice services for indoor navigation. A Raspberry Pi 3 Model B is used as the element of the hardware to provide our system with intelligent characteristics. You can trigger the speech service using the {""}Alexa{""} keyword. Using the voice command, the skill/ application we created can be initiated. It operates a script on the cloud once Alexa is enabled, which runs a subroutine on the Raspberry Pi 3 in-turn to provide a path for that specific place. Once the Raspberry Pi calculation is finished, it sends the message back to Alexa. Alexa transforms the text into a voice and informs the user path. Â© BEIESP.",2019,"Artificial Intelligence, Global Positioning System, Raspberry Pi, Voice command",004.pdf,004
InProceedings,Design of seamless multi-modal interaction framework for intelligent virtual agents in wearable mixed reality environment,"In this paper, we present the design of a multimodal interaction framework for intelligent virtual agents in wearable mixed reality environments, especially for interactive applications at museums, botanical gardens, and similar places. These places need engaging and no-repetitive digital content delivery to maximize user involvement. An intelligent virtual agent is a promising mode for both purposes. Premises of framework is wearable mixed reality provided by MR devices supporting spatial mapping. We envisioned a seamless interaction framework by integrating potential features of spatial mapping, virtual character animations, speech recognition, gazing, domain-specific chatbot and object recognition to enhance virtual experiences and communication between users and virtual agents. By applying a modular approach and deploying computationally intensive modules on cloud-platform, we achieved a seamless virtual experience in a device with limited resources. Human-like gaze and speech interaction with a virtual agent made it more interactive. Automated mapping of body animations with the content of a speech made it more engaging. In our tests, the virtual agents responded within 2-4 seconds after the user query. The strength of the framework is flexibility and adaptability. It can be adapted to any wearable MR device supporting spatial mapping. Â© 2019 Association for Computing Machinery.",2019,NA,021.pdf,021
InProceedings,On hyper-local conversational agents in urban settings,"Conversational agents are increasingly becoming digital partners in our everyday computational experiences. Although rich, and fresh in content, these agents are completely oblivious to users' locality beyond geospatial weather and traffic conditions. In this position statement, we envisage a brand-new class of conversational agents that are hyper-local, embedded deeply in a local neighbourhood, e.g., at urban landmarks - providing rich, purposeful, detail, and in some cases playful information relevant to a neighbourhood. By design, these agents are spatially constrained, and one can only interact with them once she is in close vicinity at street-level granularity. Learning from quantitative (n = 1992) and qualitative (n = 21) studies, we identify a set of information that these agents must accommodate. Finally, we discuss the technical architecture of this class of conversational agents that leverages covert communication channel, edge AI and on-body devices for offering such hyper-local information access. Â© 2019 Copyright held by the owner/author(s).",2019,"Citizen Engagement, Conversational Agent, Edge AI, Spontaneous Interaction",038.pdf,038
Book,An Approach to Conversational Recommendation of Restaurants,"In this paper, we propose an approach based on the integration of a chatbot module, a location-based service, and a recommendation algorithm. This approach has been deployed for restaurant recommendation, tested on a sample of 50 real users, and compared with some state-of-the-art algorithms. The preliminary experimental results showed the benefits of the proposed approach in terms of performance. An ANOVA test enabled us to verify the statistical significance of the obtained findings. Â© Springer Nature Switzerland AG 2019.",2019,"Cold-start, Conversational recommender systems, Location-based services",007.pdf,007
InProceedings,Anna: A virtual assistant to interact with puglia digital library (discussion paper),"In the last years, a huge amount of data has been released by private and public bodies as Linked Open Data. By their inner nature, these data contain rich semantic information that can be automatically processed by software agents and explored by humans via visual tools or structured SPARQL queries. Although they result useful for many tasks, these latter approaches miss the simplicity of the interfaces based on interactions via natural language implemented in modern virtual assistants. In this paper, we present a system able to assist the user in exploring the knowledge exposed by the Puglia Digital Library containing information and data associated with digital goods related to the Apulia region in Italy. We show how to interact with the Digital Library by means of a virtual assistant and how, thanks to its publication as Linked Open Data, it is possible to easily integrate it on-the-fly with external knowledge sources such as geographical ones. Copyright Â© 2019 for the individual papers by the papers authors.",2019,"Chatbot, Digital Libraries, Linked Open Data, Vocal Assistant",008.pdf,008
Article,PAVAL: A location-aware virtual personal assistant for retrieving geolocated points of interest and location-based services,"Today most of the users on the move require contextualized local and georeferenced information. Several solutions aim to meet these trends, thus assisting users and satisfying their needs and preferences, such as virtual assistants and Location-Aware Recommender Systems (LARS), both in commercial and research literature. However, general purpose virtual assistants usually have to manage large domains, dealing with big amounts of data and online resources, losingfocus on more specific requirements and local information. On the other hand, traditional recommender systems are based on filtering techniques and contextual knowledge, and they usually do not rely on Natural Language Processing (NLP) features on usersâ€™ queries, which are useful to understand and contextualize usersâ€™ necessities on the spot. Therefore, comprehending the actual usersâ€™ information needs and other key information that can be included in the user query, such as geographical references, is a challenging task which is not yet fully accomplished by current state-of-the-art solutions. In this paper, we propose Paval (Location-Aware Virtual Personal Assistant 2), a semantic assisting engine for suggesting local points of interest (POIs) and services by analyzing usersâ€™ natural language queries, in order to estimate the information need and potential geographic references expressed by the users. The system exploits NLP and semantic techniques providing as output recommendations on local geolocated POIs and services which best match the usersâ€™ requests, retrieved by querying our semantic Km4City Knowledge Base. The proposed system is validated against the most popular virtual assistants, such as Google Assistant, Apple Siri and Microsoft Cortana, focusing the assessment on the request of geolocated POIs and services, showing very promising capabilities in successfully estimating the usersâ€™ information needs and multiple geographic references. Â© 2018 The Authors",2019,"Geographic information retrieval, Geocoding, Geoparsing, Location-aware recommender systems, Natural language processing, Semantic web technologies, User-intent detection, Virtual personal assistants",040.pdf,040
Book,Combination of Semantic Localization and Conversational Skills for Assistive Robots,"The recognition of objects and their features is a fundamental task for social robots that could be improved with the combination of different sources of information, such as the ones provided by visual or speech understanding systems. In this paper, we present a first approach to fusion semantic localization and conversational skills for social robots which may act as assistants. Our solution is based on a mobile robot that is able to detect and recognize objects from an environment and store them in its base of knowledge to later act as an assistant for any user who is searching for any object. In the conversation the robot tries to help the user to find a specific object depending of the location and the features of the object which is looking for. The proposal has been empirically evaluated within a research lab where the robot recognizes objects in the environment and the users require, by means of speech commands, finding suitable objects that are placed in the environment. Â© 2019, Springer Nature Switzerland AG.",2019,"Artificial vision, Assistive robotics, Human-robot interaction, Smart homes, Speech recognition",016.pdf,016
Book,Creating Weather Narratives,"Information can be conveyed to the user by means of a narrative, modeled according to the userâ€™s context. A case in point is the weather, which can be perceived differently and with distinct levels of importance according to the userâ€™s context. For example, for a blind person, the weather is an important element to plan and move between locations. In fact, weather can make it very difficult or even impossible for a blind person to successfully negotiate a path and navigate from one place to another. To provide proper information, narrated and delivered according to the personâ€™s context, this paper proposes a project for the creation of weather narratives, targeted at specific types of users and contexts. The proposalâ€™s main objective is to add value to the data, acquired through the observation of weather systems, by interpreting that data, in order to identify relevant information and automatically create narratives, in a conversational way or with machine metadata language. These narratives should communicate specific aspects of the evolution of the weather systems in an efficient way, providing knowledge and insight in specific contexts and for specific purposes. Currently, there are several language generatorâ€™ systems, which automatically create weather forecast reports, based on previously processed and synthesized information. This paper, proposes a wider and more comprehensive approach to the weather systems phenomena, proposing a full process, from the raw data to a contextualized narration, thus providing a methodology and a tool that might be used for various contexts and weather systems. Â© 2019, Springer Nature Switzerland AG.",2019,NA,020.pdf,020
Article,Cloud-based dialog navigation agent system for service robots,"The conventional humanâ€“robot interactions of robotic navigation systems must rely on strict language instructions and numerous button operations. In this study, a cloud-based dialog navigation agent (CDNA) system was designed for a campus navigation robot (CNR) that provides navigation services to students, school visitors, and people with impaired vision. The CDNA is based on a lightweight beliefâ€“desireâ€“intention (BDI) software architecture (i.e., CellS, a cell-inspired efficient software framework), which is a goal-oriented and dynamic parallel framework. The proposed CDNA system has the following three primary functions: (1) conversational navigation service, (2) immediate path planning and path modification, and (3) location guide and place evaluation. The system can be applied to regional navigation guidance services such as campus tours. The CellS-based CDNA uses a natural language processing (NLP) technology to analyze the semantics of user statements and uses dialog to eliminate ambiguity in language to improve interaction with users. In this study, 15 items for three different navigation systems were evaluated, which demonstrated that the CDNA is advantageous in terms of interactivity and usability. The CellS-based CDNA can achieve an average speedup of 1.75 times in seven data sets. Therefore, the CDNA possesses the following advantages: high interactivity, high usability, and high performance. Â© MYU K.K.",2019,"Navigation, Natural language processing, Artificial intelligence, Automation, Robotics",012.pdf,012
Book,Place questions and human-generated answers: A data analysis approach,"This paper investigates place-related questions submitted to search systems and their human-generated answers. Place-based search is motivated by the need to identify places matching some criteria, to identify them in space or relative to other places, or to characterize the qualities of such places. Human place-related questions have thus far been insufficiently studied and differ strongly from typical keyword queries. They thus challenge todayâ€™s search engines providing only rudimentary geographic information retrieval support. We undertake an analysis of the patterns in place-based questions using a large-scale dataset of questions/answers, MS MARCO V2.1. The results of this study reveal patterns that can inform the design of conversational search systems and in-situ assistance systems, such as autonomous vehicles. Â© Springer Nature Switzerland AG 2020.",2020,"Geographic information retrieval, Geographic questions, Query classification, Question answering systems, Web search queries",041.pdf,041
Article,Ask Diana: A Keyword-Based Chatbot System for Water-Related Disaster Management,"This research developed a keyword-based chatbot system, Ask Diana, for water-related disaster management. Disaster management has been considered difficult and tedious due to the complex characteristics of disaster-related data. To deal with this problem, this research developed a chatbot system with a water-related disaster database, a user intent mechanism, and an intuitive mobile-device-based user interface. With such a system, users are able to access important data or information they need for decision making by directly asking the proposed chatbot or operating the image-based menus. The system was validated through a usability test and a six-month field test. The results demonstrated that Ask Diana can help related personnel access disaster data intuitively and develop corresponding response strategies efficiently.",NA,NA,101.pdf,101
